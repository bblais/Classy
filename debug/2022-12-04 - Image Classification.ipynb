{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dc1a37f-1a79-4ee6-a4e7-a58e07d03b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeeb2e8b-68b8-4b29-aacd-b9f547c95d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version  1.0.7\n",
      "Version:  0.0.39\n"
     ]
    }
   ],
   "source": [
    "from classy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40b6b058-c9ed-43d7-a390-65ff37a6a960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[red]: 60 files found\n",
      "[white]: 49 files found\n",
      "[black]: 67 files found\n"
     ]
    }
   ],
   "source": [
    "images=image.load_images('images/square images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b27cc742-d51e-4a98-9c6d-af3176429a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 vectors of length 7500\n",
      "Feature names: 'p0', 'p1', 'p2', 'p3', 'p4'  , ... ,  'p7495', 'p7496', 'p7497', 'p7498', 'p7499'  (7500 features)\n",
      "Target values given.\n",
      "Target names: 'red', 'white', 'black'\n",
      "Mean:  [116.77840909 124.65909091 117.86931818 ... 183.26704545 186.98295455\n",
      " 178.26704545]\n",
      "Median:  [151.  165.  155.5 ... 184.  189.  180. ]\n",
      "Stddev:  [67.04477634 71.35886999 70.85997694 ...  5.98504237 12.83172313\n",
      " 12.64516815]\n"
     ]
    }
   ],
   "source": [
    "data=image.images_to_vectors(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7490b17f-8e37-4669-9c9c-6988dd7f1d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.standardize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bce0fe5-c99c-4433-b08b-d75db790e0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 vectors of length 7500\n",
      "Feature names: 'p0', 'p1', 'p2', 'p3', 'p4'  , ... ,  'p7495', 'p7496', 'p7497', 'p7498', 'p7499'  (7500 features)\n",
      "Target values given.\n",
      "Target names: 'red', 'white', 'black'\n",
      "Mean:  [-4.41565976e-17  4.47874061e-17 -9.14672378e-17 ... -1.85205386e-15\n",
      "  9.52678593e-16 -1.04083409e-15]\n",
      "Median:  [0.51042889 0.56532438 0.53105693 ... 0.12246439 0.1571921  0.1370448 ]\n",
      "Stddev:  [1. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "summary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80f8209b-342c-4dfc-a67c-076c5f8b12b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector shape:  (176, 7500)\n",
      "Train vector shape:  (140, 7500)\n",
      "Test vector shape:  (36, 7500)\n"
     ]
    }
   ],
   "source": [
    "data_train,data_test=split(data,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c920ac4-5f12-4761-bcb3-9ba2a8507557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Training Set: 100.0\n",
      "On Test Set: 100.0\n"
     ]
    }
   ],
   "source": [
    "C=NaiveBayes()\n",
    "C.fit(data_train.vectors,data_train.targets)\n",
    "print(\"On Training Set:\",C.percent_correct(data_train.vectors,data_train.targets))\n",
    "print(\"On Test Set:\",C.percent_correct(data_test.vectors,data_test.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c19dad4-cd12-4241-9b9b-ac3d668e7a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.save('test_save_naivebayes_images.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c708157-3c60-4b5e-a58f-811162e89ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Training Set: 100.0\n",
      "On Test Set: 100.0\n"
     ]
    }
   ],
   "source": [
    "C1=NaiveBayes()\n",
    "C1.load('test_save_naivebayes_images.json')\n",
    "print(\"On Training Set:\",C1.percent_correct(data_train.vectors,data_train.targets))\n",
    "print(\"On Test Set:\",C1.percent_correct(data_test.vectors,data_test.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f15dd-e785-4e8c-9ab6-8f3f8bbca193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "830b4636-9302-4eac-a2fd-c97b6ce84102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Training Set: 99.28571428571429\n",
      "On Test Set: 100.0\n"
     ]
    }
   ],
   "source": [
    "C=kNearestNeighbor()\n",
    "C.fit(data_train.vectors,data_train.targets)\n",
    "print(\"On Training Set:\",C.percent_correct(data_train.vectors,data_train.targets))\n",
    "print(\"On Test Set:\",C.percent_correct(data_test.vectors,data_test.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9970f51-a752-4c7b-9171-a025a3918d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.save('test_save_knn_images.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45418feb-7625-4afe-9763-c37ba2279b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Training Set: 99.28571428571429\n",
      "On Test Set: 100.0\n"
     ]
    }
   ],
   "source": [
    "C1=kNearestNeighbor()\n",
    "C1.load('test_save_knn_images.json')\n",
    "print(\"On Training Set:\",C1.percent_correct(data_train.vectors,data_train.targets))\n",
    "print(\"On Test Set:\",C1.percent_correct(data_test.vectors,data_test.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1a71148-3fea-463c-9669-3e566378f9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Training Set: 100.0\n",
      "On Test Set: 100.0\n"
     ]
    }
   ],
   "source": [
    "C=RCE()\n",
    "C.fit(data_train.vectors,data_train.targets)\n",
    "print(\"On Training Set:\",C.percent_correct(data_train.vectors,data_train.targets))\n",
    "print(\"On Test Set:\",C.percent_correct(data_test.vectors,data_test.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74a10e16-9591-47e7-b77d-dcfab883a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.save('test_save_rce_images.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "810fe3c2-0e59-458e-8ea8-d228ee597bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Training Set: 100.0\n",
      "On Test Set: 100.0\n"
     ]
    }
   ],
   "source": [
    "C1=RCE()\n",
    "C1.load('test_save_rce_images.json')\n",
    "print(\"On Training Set:\",C1.percent_correct(data_train.vectors,data_train.targets))\n",
    "print(\"On Test Set:\",C1.percent_correct(data_test.vectors,data_test.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0f7696a-d5a8-4f68-9326-fa377ea41bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Training Set: 100.0\n",
      "On Test Set: 97.22222222222221\n"
     ]
    }
   ],
   "source": [
    "C=CSC()\n",
    "C.fit(data_train.vectors,data_train.targets)\n",
    "print(\"On Training Set:\",C.percent_correct(data_train.vectors,data_train.targets))\n",
    "print(\"On Test Set:\",C.percent_correct(data_test.vectors,data_test.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2bec6044-781c-4a84-8668-a68c68fff0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.save('test_save_csc_images.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e838a98c-ba33-47c9-bc9a-cfad2e064fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Training Set: 100.0\n",
      "On Test Set: 97.22222222222221\n"
     ]
    }
   ],
   "source": [
    "C1=CSC()\n",
    "C1.load('test_save_csc_images.json')\n",
    "print(\"On Training Set:\",C1.percent_correct(data_train.vectors,data_train.targets))\n",
    "print(\"On Test Set:\",C1.percent_correct(data_test.vectors,data_test.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd28255e-8fed-43b6-a239-7c0432abcaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 7500\n",
      "Number of categories: 3\n"
     ]
    }
   ],
   "source": [
    "number_of_features=data_train.vectors.shape[1]\n",
    "number_of_categories=len(set(data_train.targets))  # the types of pieces\n",
    "print(\"Number of features:\",number_of_features)\n",
    "print(\"Number of categories:\",number_of_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a42e6b-6889-4de7-9392-233fbb8531e0",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49bb8a3f-a412-4fba-b066-bf9d178a3076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer       filters  size              input                output\n",
      "   0 input                   140 x   1 x   1 x7500   ->   140 x   1 x   1 x7500\n",
      "   1 connected               140 x   1 x   1 x7500   ->   140 x   3\n",
      "   2 cost                    140 x   1 x   1 x   3   ->   140 x   1 x   1 x   3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 3000/3000 [00:52<00:00, 56.67it/s]\n"
     ]
    }
   ],
   "source": [
    "C=NumPyNetBackProp({\n",
    "    'input':number_of_features,               # number of features\n",
    "    'output':(number_of_categories,'linear'),  # number of classes\n",
    "    'cost':'mse',\n",
    "})\n",
    "C.fit(data_train.vectors,data_train.targets,epochs=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd1ae1b8-da35-45bf-ab76-7142bebcd66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Training Set: 100.0\n",
      "On Test Set: 86.11111111111111\n"
     ]
    }
   ],
   "source": [
    "print(\"On Training Set:\",C.percent_correct(data_train.vectors,data_train.targets))\n",
    "print(\"On Test Set:\",C.percent_correct(data_test.vectors,data_test.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ffd11ff8-a8e2-43cc-88dd-e6a6899cdcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.save('test_save_perceptron_images.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e60ae55a-c73d-45f4-ad66-d050729c94b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer       filters  size              input                output\n",
      "   0 input                     1 x   1 x   1 x7500   ->     1 x   1 x   1 x7500\n",
      "   1 connected                 1 x   1 x   1 x7500   ->     1 x   3\n",
      "   2 cost                      1 x   1 x   1 x   3   ->     1 x   1 x   1 x   3\n",
      "On Training Set: 100.0\n",
      "On Test Set: 86.11111111111111\n"
     ]
    }
   ],
   "source": [
    "C1=NumPyNetBackProp()\n",
    "C1.load('test_save_perceptron_images.json')\n",
    "print(\"On Training Set:\",C1.percent_correct(data_train.vectors,data_train.targets))\n",
    "print(\"On Test Set:\",C1.percent_correct(data_test.vectors,data_test.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e7b3e5-66c1-4013-b829-f106128daf63",
   "metadata": {},
   "source": [
    "## Backprop - Multilayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07bcb73d-b29b-41d0-83cd-d818fd8c4ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer       filters  size              input                output\n",
      "   0 input                   140 x   1 x   1 x7500   ->   140 x   1 x   1 x7500\n",
      "   1 connected               140 x   1 x   1 x7500   ->   140 x  15\n",
      "   2 connected               140 x   1 x   1 x  15   ->   140 x   3\n",
      "   3 cost                    140 x   1 x   1 x   3   ->   140 x   1 x   1 x   3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 3000/3000 [01:03<00:00, 47.17it/s]\n"
     ]
    }
   ],
   "source": [
    "C=NumPyNetBackProp({\n",
    "    'input':number_of_features,               # number of features\n",
    "    'hidden':[(15,'logistic'),],   # this size is \"arbitrary\"\n",
    "    'output':(number_of_categories,'logistic'),  # number of classes\n",
    "    'cost':'mse',\n",
    "})\n",
    "C.fit(data_train.vectors,data_train.targets,epochs=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a176ecf-4000-44c1-a351-f1bba283a037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Training Set: 100.0\n",
      "On Test Set: 100.0\n"
     ]
    }
   ],
   "source": [
    "print(\"On Training Set:\",C.percent_correct(data_train.vectors,data_train.targets))\n",
    "print(\"On Test Set:\",C.percent_correct(data_test.vectors,data_test.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c631096c-8608-4c76-8093-23417fdf56a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.save('test_save_backprop_images.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05fabe2d-0c64-4c90-b9be-d2dbc4a13333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer       filters  size              input                output\n",
      "   0 input                     1 x   1 x   1 x7500   ->     1 x   1 x   1 x7500\n",
      "   1 connected                 1 x   1 x   1 x7500   ->     1 x  15\n",
      "   2 connected                 1 x   1 x   1 x  15   ->     1 x   3\n",
      "   3 cost                      1 x   1 x   1 x   3   ->     1 x   1 x   1 x   3\n",
      "On Training Set: 100.0\n",
      "On Test Set: 100.0\n"
     ]
    }
   ],
   "source": [
    "C1=NumPyNetBackProp()\n",
    "C1.load('test_save_backprop_images.json')\n",
    "print(\"On Training Set:\",C1.percent_correct(data_train.vectors,data_train.targets))\n",
    "print(\"On Test Set:\",C1.percent_correct(data_test.vectors,data_test.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc209b-4ea9-4fa0-8d13-3c6b38c96b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
