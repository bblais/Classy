{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version  1.0.4\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "'''\n",
    "Little example on how to use the Network class to create a model and perform\n",
    "a basic classification of the MNIST dataset\n",
    "'''\n",
    "\n",
    "#from NumPyNet.layers.input_layer import Input_layer\n",
    "from NumPyNet.layers.connected_layer import Connected_layer\n",
    "from NumPyNet.layers.convolutional_layer import Convolutional_layer\n",
    "from NumPyNet.layers.maxpool_layer import Maxpool_layer\n",
    "from NumPyNet.layers.softmax_layer import Softmax_layer\n",
    "# from NumPyNet.layers.dropout_layer import Dropout_layer\n",
    "# from NumPyNet.layers.cost_layer import Cost_layer\n",
    "# from NumPyNet.layers.cost_layer import cost_type\n",
    "from NumPyNet.layers.batchnorm_layer import BatchNorm_layer\n",
    "from NumPyNet.network import Network\n",
    "from NumPyNet.optimizer import Adam\n",
    "# from NumPyNet.optimizer import Adam, SGD, Momentum\n",
    "from NumPyNet.utils import to_categorical\n",
    "from NumPyNet.utils import from_categorical\n",
    "from NumPyNet.metrics import mean_accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "__author__ = ['Mattia Ceccarelli', 'Nico Curti']\n",
    "__email__ = ['mattia.ceccarelli3@studio.unibo.it', 'nico.curti2@unibo.it']\n",
    "\n",
    "\n",
    "def accuracy (y_true, y_pred):\n",
    "  '''\n",
    "  Temporary metrics to overcome \"from_categorical\" missing in standard metrics\n",
    "  '''\n",
    "  truth = from_categorical(y_true)\n",
    "  predicted = from_categorical(y_pred)\n",
    "  return mean_accuracy_score(truth, predicted)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (1797, 8, 3, 8)\n",
      "*************************************\n",
      "\n",
      " Total input dimension: (512, 8, 3, 8) \n",
      "\n",
      "**************MODEL SUMMARY***********\n",
      "layer       filters  size              input                output\n",
      "   0 input                   128 x   8 x   3 x   8   ->   128 x   8 x   3 x   8\n",
      "   1 conv     32 3 x 3 / 1   128 x   8 x   3 x   8   ->   128 x   8 x   3 x  32  0.000 BFLOPs\n",
      "   2 batchnorm                       8 x   3 x  32 image\n",
      "   3 max         2 x 2 / 1   128 x   8 x   3 x  32   ->   128 x   7 x   2 x  32\n",
      "   4 connected               128 x   7 x   2 x  32   ->   128 x 100\n",
      "   5 batchnorm                       1 x   1 x 100 image\n",
      "   6 connected               128 x   1 x   1 x 100   ->   128 x  10\n",
      "   7 softmax x entropy                                    128 x   1 x   1 x  10\n",
      "\n",
      "***********START TRAINING***********\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********START TESTING**************\n",
      "\n",
      "\u001b[K300/300 |██████████████████████████████████████████████████| (0.0 sec/iter) loss: 0.225\n",
      "Prediction on 300 samples took 0.0 sec\n",
      "\n",
      "Loss Score: 0.105\n",
      "Accuracy Score: 0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X, y = digits.images, digits.target\n",
    "\n",
    "# del digits\n",
    "\n",
    "# add channels to images\n",
    "X = np.asarray([np.dstack((x, x, x)) for x in X])\n",
    "X = X.transpose(0, 2, 3, 1)\n",
    "print(\"X shape\",X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                  test_size=.33,\n",
    "                                                  random_state=42)\n",
    "\n",
    "batch = 128\n",
    "num_classes = len(set(y))\n",
    "\n",
    "# del X, y\n",
    "\n",
    "# normalization to [0, 1]\n",
    "X_train *= 1. / 255.\n",
    "X_test  *= 1. / 255.\n",
    "\n",
    "# reduce the size of the data set for testing\n",
    "############################################\n",
    "\n",
    "train_size = 512\n",
    "test_size  = 300\n",
    "\n",
    "X_train = X_train[:train_size, ...]\n",
    "y_train = y_train[:train_size]\n",
    "X_test  = X_test[ :test_size,  ...]\n",
    "y_test  = y_test[ :test_size]\n",
    "\n",
    "############################################\n",
    "\n",
    "n_train = X_train.shape[0]\n",
    "n_test  = X_test.shape[0]\n",
    "\n",
    "# transform y to array of dimension 10 and in 4 dimension\n",
    "y_train = to_categorical(y_train).reshape(n_train, 1, 1, -1)\n",
    "y_test  = to_categorical(y_test).reshape(n_test, 1, 1, -1)\n",
    "\n",
    "# Create the model and training\n",
    "model = Network(batch=batch, input_shape=X_train.shape[1:])\n",
    "\n",
    "model.add(Convolutional_layer(size=3, filters=32, stride=1, pad=True, activation='Relu'))\n",
    "\n",
    "model.add(BatchNorm_layer())\n",
    "\n",
    "model.add(Maxpool_layer(size=2, stride=1, padding=True))\n",
    "\n",
    "model.add(Connected_layer(outputs=100, activation='Relu'))\n",
    "\n",
    "model.add(BatchNorm_layer())\n",
    "\n",
    "model.add(Connected_layer(outputs=num_classes, activation='Linear'))\n",
    "\n",
    "model.add(Softmax_layer(spatial=True, groups=1, temperature=1.))\n",
    "# model.add(Cost_layer(cost_type=cost_type.mse))\n",
    "\n",
    "# model.compile(optimizer=SGD(lr=0.01, decay=0., lr_min=0., lr_max=np.inf))\n",
    "model.compile(optimizer=Adam(), metrics=[accuracy])\n",
    "\n",
    "print('*************************************')\n",
    "print('\\n Total input dimension: {}'.format(X_train.shape), '\\n')\n",
    "print('**************MODEL SUMMARY***********')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print('\\n***********START TRAINING***********\\n')\n",
    "\n",
    "# Fit the model on the training set\n",
    "model.fit(X=X_train, y=y_train, max_iter=10, verbose=True)\n",
    "\n",
    "print('\\n***********START TESTING**************\\n')\n",
    "\n",
    "# Test the prediction with timing\n",
    "loss, out = model.evaluate(X=X_test, truth=y_test, verbose=True)\n",
    "\n",
    "truth = from_categorical(y_test)\n",
    "predicted = from_categorical(out)\n",
    "accuracy2  = mean_accuracy_score(truth, predicted)\n",
    "\n",
    "print('\\nLoss Score: {:.3f}'.format(loss))\n",
    "print('Accuracy Score: {:.3f}'.format(accuracy2))\n",
    "# SGD : best score I could obtain was 94% with 10 epochs, lr = 0.01 %\n",
    "# Momentum : best score I could obtain was 93% with 10 epochs\n",
    "# Adam : best score I could obtain was 95% with 10 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 3, 8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "X, y = digits.images, digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]: 180 files found\n",
      "[0]: 178 files found\n",
      "[7]: 179 files found\n",
      "[6]: 181 files found\n",
      "[1]: 182 files found\n",
      "[8]: 174 files found\n",
      "[4]: 181 files found\n",
      "[3]: 183 files found\n",
      "[2]: 177 files found\n",
      "[5]: 182 files found\n"
     ]
    }
   ],
   "source": [
    "import classy\n",
    "images=classy.image.load_images('data/digits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['DESCR', 'files', 'data', 'targets', 'target_names'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[red]: 192 files found\n",
      "[white]: 128 files found\n",
      "[black]: 192 files found\n"
     ]
    }
   ],
   "source": [
    "images_color=classy.image.load_images('data/all_pieces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 66, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_color.data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 3, 24, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = np.asarray([np.dstack((x, x, x)) for x in X])\n",
    "X2 = X2.transpose(0, 2, 3, 1)\n",
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((512, 57, 66, 4), (512, 66, 4, 57))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im=images_color\n",
    "if len(im.data[0].shape)==2:  # grayscale\n",
    "    X=np.array(im.data)\n",
    "    X2 = np.asarray([np.dstack((x, x, x)) for x in X])\n",
    "    X2 = X2.transpose(0, 2, 3, 1)\n",
    "else:\n",
    "    X=np.array(im.data)\n",
    "    X2 = X[:]\n",
    "    X2 = X2.transpose(0, 2, 3, 1)\n",
    "    \n",
    "    \n",
    "X.shape,X2.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images\n",
      "408 images of shape (57, 66, 4)\n",
      "Target values given.\n",
      "Target names: 'red', 'white', 'black'\n",
      "Images\n",
      "104 images of shape (57, 66, 4)\n",
      "Target values given.\n",
      "Target names: 'red', 'white', 'black'\n"
     ]
    }
   ],
   "source": [
    "images=images_color\n",
    "images_train,images_test=classy.image.split(images,verbose=False)\n",
    "classy.summary(images_train)\n",
    "classy.summary(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "im=images_train\n",
    "n_train=len(im.data)\n",
    "num_classes=len(im.target_names)\n",
    "if len(im.data[0].shape)==2:  # grayscale\n",
    "    X=np.array(im.data)\n",
    "    X = np.asarray([np.dstack((x, x, x)) for x in X])\n",
    "    X = X.transpose(0, 2, 3, 1)\n",
    "else:\n",
    "    X=np.array(im.data)\n",
    "    X = X.transpose(0, 2, 3, 1)\n",
    "    \n",
    "# normalization to [0, 1]\n",
    "X = X/X.max()\n",
    "\n",
    "y = to_categorical(im.targets).reshape(n_train, 1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************\n",
      "\n",
      " Total input dimension: (512, 8, 3, 8) \n",
      "\n",
      "**************MODEL SUMMARY***********\n",
      "layer       filters  size              input                output\n",
      "   0 input                   408 x  66 x   4 x  57   ->   408 x  66 x   4 x  57\n",
      "   1 conv     32 3 x 3 / 1   408 x  66 x   4 x  57   ->   408 x  66 x   4 x  32  0.009 BFLOPs\n",
      "   2 batchnorm                      66 x   4 x  32 image\n",
      "   3 max         2 x 2 / 1   408 x  66 x   4 x  32   ->   408 x  65 x   3 x  32\n",
      "   4 connected               408 x  65 x   3 x  32   ->   408 x 100\n",
      "   5 batchnorm                       1 x   1 x 100 image\n",
      "   6 connected               408 x   1 x   1 x 100   ->   408 x   3\n",
      "   7 softmax x entropy                                    408 x   1 x   1 x   3\n",
      "\n",
      "***********START TRAINING***********\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:17<00:00,  7.74s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create the model and training\n",
    "model = Network(batch=n_train, input_shape=X.shape[1:])\n",
    "\n",
    "model.add(Convolutional_layer(size=3, filters=32, stride=1, pad=True, activation='Relu'))\n",
    "\n",
    "model.add(BatchNorm_layer())\n",
    "\n",
    "model.add(Maxpool_layer(size=2, stride=1, padding=True))\n",
    "\n",
    "model.add(Connected_layer(outputs=100, activation='Relu'))\n",
    "\n",
    "model.add(BatchNorm_layer())\n",
    "\n",
    "model.add(Connected_layer(outputs=num_classes, activation='Linear'))\n",
    "\n",
    "model.add(Softmax_layer(spatial=True, groups=1, temperature=1.))\n",
    "# model.add(Cost_layer(cost_type=cost_type.mse))\n",
    "\n",
    "# model.compile(optimizer=SGD(lr=0.01, decay=0., lr_min=0., lr_max=np.inf))\n",
    "model.compile(optimizer=Adam(), metrics=[accuracy])\n",
    "\n",
    "print('*************************************')\n",
    "print('\\n Total input dimension: {}'.format(X_train.shape), '\\n')\n",
    "print('**************MODEL SUMMARY***********')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print('\\n***********START TRAINING***********\\n')\n",
    "\n",
    "# Fit the model on the training set\n",
    "model.fit(X=X, y=y, max_iter=10, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "im=images_test\n",
    "n_test=len(im.data)\n",
    "num_classes=len(im.target_names)\n",
    "if len(im.data[0].shape)==2:  # grayscale\n",
    "    X=np.array(im.data)\n",
    "    X = np.asarray([np.dstack((x, x, x)) for x in X])\n",
    "    X = X.transpose(0, 2, 3, 1)\n",
    "else:\n",
    "    X=np.array(im.data)\n",
    "    X = X.transpose(0, 2, 3, 1)\n",
    "    \n",
    "# normalization to [0, 1]\n",
    "X = X/X.max()\n",
    "\n",
    "y = to_categorical(im.targets).reshape(n_test, 1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K104/104 |██████████████████████████████████████████████████| (0.2 sec/iter) loss: 0.404\n",
      "Prediction on 104 samples took 0.2 sec\n",
      "\n",
      "Loss Score: 0.404\n",
      "Accuracy Score: 0.923\n"
     ]
    }
   ],
   "source": [
    "# Test the prediction with timing\n",
    "model.batch=n_test\n",
    "loss, out = model.evaluate(X=X, truth=y, verbose=True)\n",
    "\n",
    "truth = from_categorical(y)\n",
    "predicted = from_categorical(out)\n",
    "accuracy2  = mean_accuracy_score(truth, predicted)\n",
    "\n",
    "print('\\nLoss Score: {:.3f}'.format(loss))\n",
    "print('Accuracy Score: {:.3f}'.format(accuracy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 8, 3, 8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
