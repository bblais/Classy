{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************\n",
      "\n",
      " Total input dimension: (512, 8, 3, 8) \n",
      "\n",
      "**************MODEL SUMMARY***********\n",
      "layer       filters  size              input                output\n",
      "   0 input                   128 x   8 x   3 x   8   ->   128 x   8 x   3 x   8\n",
      "   1 conv     32 3 x 3 / 1   128 x   8 x   3 x   8   ->   128 x   8 x   3 x  32  0.000 BFLOPs\n",
      "   2 batchnorm                       8 x   3 x  32 image\n",
      "   3 max         2 x 2 / 1   128 x   8 x   3 x  32   ->   128 x   7 x   2 x  32\n",
      "   4 connected               128 x   7 x   2 x  32   ->   128 x 100\n",
      "   5 batchnorm                       1 x   1 x 100 image\n",
      "   6 connected               128 x   1 x   1 x 100   ->   128 x  10\n",
      "   7 softmax x entropy                                    128 x   1 x   1 x  10\n",
      "\n",
      "***********START TRAINING***********\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[K512/512 |██████████████████████████████████████████████████| (0.1 sec/iter) loss: 1.817 accuracy: 0.826\n",
      "\n",
      "Epoch 2/10\n",
      "\u001b[K512/512 |██████████████████████████████████████████████████| (0.1 sec/iter) loss: 0.785 accuracy: 0.914\n",
      "\n",
      "Epoch 3/10\n",
      "\u001b[K512/512 |██████████████████████████████████████████████████| (0.1 sec/iter) loss: 0.481 accuracy: 0.943\n",
      "\n",
      "Epoch 4/10\n",
      "\u001b[K512/512 |██████████████████████████████████████████████████| (0.1 sec/iter) loss: 0.356 accuracy: 0.963\n",
      "\n",
      "Epoch 5/10\n",
      "\u001b[K512/512 |██████████████████████████████████████████████████| (0.1 sec/iter) loss: 0.280 accuracy: 0.975\n",
      "\n",
      "Epoch 6/10\n",
      "\u001b[K512/512 |██████████████████████████████████████████████████| (0.1 sec/iter) loss: 0.228 accuracy: 0.977\n",
      "\n",
      "Epoch 7/10\n",
      "\u001b[K512/512 |██████████████████████████████████████████████████| (0.1 sec/iter) loss: 0.189 accuracy: 0.986\n",
      "\n",
      "Epoch 8/10\n",
      "\u001b[K512/512 |██████████████████████████████████████████████████| (0.1 sec/iter) loss: 0.161 accuracy: 0.992\n",
      "\n",
      "Epoch 9/10\n",
      "\u001b[K512/512 |██████████████████████████████████████████████████| (0.1 sec/iter) loss: 0.137 accuracy: 0.994\n",
      "\n",
      "Epoch 10/10\n",
      "\u001b[K512/512 |██████████████████████████████████████████████████| (0.1 sec/iter) loss: 0.117 accuracy: 0.996\n",
      "\n",
      "Training on 10 epochs took 4.2 sec\n",
      "\n",
      "***********START TESTING**************\n",
      "\n",
      "\u001b[K300/300 |██████████████████████████████████████████████████| (0.0 sec/iter) loss: 0.225\n",
      "Prediction on 300 samples took 0.0 sec\n",
      "\n",
      "Loss Score: 0.105\n",
      "Accuracy Score: 0.937\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "'''\n",
    "Little example on how to use the Network class to create a model and perform\n",
    "a basic classification of the MNIST dataset\n",
    "'''\n",
    "\n",
    "#from NumPyNet.layers.input_layer import Input_layer\n",
    "from NumPyNet.layers.connected_layer import Connected_layer\n",
    "from NumPyNet.layers.convolutional_layer import Convolutional_layer\n",
    "from NumPyNet.layers.maxpool_layer import Maxpool_layer\n",
    "from NumPyNet.layers.softmax_layer import Softmax_layer\n",
    "# from NumPyNet.layers.dropout_layer import Dropout_layer\n",
    "# from NumPyNet.layers.cost_layer import Cost_layer\n",
    "# from NumPyNet.layers.cost_layer import cost_type\n",
    "from NumPyNet.layers.batchnorm_layer import BatchNorm_layer\n",
    "from NumPyNet.network import Network\n",
    "from NumPyNet.optimizer import Adam\n",
    "# from NumPyNet.optimizer import Adam, SGD, Momentum\n",
    "from NumPyNet.utils import to_categorical\n",
    "from NumPyNet.utils import from_categorical\n",
    "from NumPyNet.metrics import mean_accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "__author__ = ['Mattia Ceccarelli', 'Nico Curti']\n",
    "__email__ = ['mattia.ceccarelli3@studio.unibo.it', 'nico.curti2@unibo.it']\n",
    "\n",
    "\n",
    "def accuracy (y_true, y_pred):\n",
    "  '''\n",
    "  Temporary metrics to overcome \"from_categorical\" missing in standard metrics\n",
    "  '''\n",
    "  truth = from_categorical(y_true)\n",
    "  predicted = from_categorical(y_pred)\n",
    "  return mean_accuracy_score(truth, predicted)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  np.random.seed(123)\n",
    "\n",
    "  digits = datasets.load_digits()\n",
    "  X, y = digits.images, digits.target\n",
    "\n",
    "  # del digits\n",
    "\n",
    "  # add channels to images\n",
    "  X = np.asarray([np.dstack((x, x, x)) for x in X])\n",
    "  X = X.transpose(0, 2, 3, 1)\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                      test_size=.33,\n",
    "                                                      random_state=42)\n",
    "\n",
    "  batch = 128\n",
    "  num_classes = len(set(y))\n",
    "\n",
    "  # del X, y\n",
    "\n",
    "  # normalization to [0, 1]\n",
    "  X_train *= 1. / 255.\n",
    "  X_test  *= 1. / 255.\n",
    "\n",
    "  # reduce the size of the data set for testing\n",
    "  ############################################\n",
    "\n",
    "  train_size = 512\n",
    "  test_size  = 300\n",
    "\n",
    "  X_train = X_train[:train_size, ...]\n",
    "  y_train = y_train[:train_size]\n",
    "  X_test  = X_test[ :test_size,  ...]\n",
    "  y_test  = y_test[ :test_size]\n",
    "\n",
    "  ############################################\n",
    "\n",
    "  n_train = X_train.shape[0]\n",
    "  n_test  = X_test.shape[0]\n",
    "\n",
    "  # transform y to array of dimension 10 and in 4 dimension\n",
    "  y_train = to_categorical(y_train).reshape(n_train, 1, 1, -1)\n",
    "  y_test  = to_categorical(y_test).reshape(n_test, 1, 1, -1)\n",
    "\n",
    "  # Create the model and training\n",
    "  model = Network(batch=batch, input_shape=X_train.shape[1:])\n",
    "\n",
    "  model.add(Convolutional_layer(size=3, filters=32, stride=1, pad=True, activation='Relu'))\n",
    "\n",
    "  model.add(BatchNorm_layer())\n",
    "\n",
    "  model.add(Maxpool_layer(size=2, stride=1, padding=True))\n",
    "\n",
    "  model.add(Connected_layer(outputs=100, activation='Relu'))\n",
    "\n",
    "  model.add(BatchNorm_layer())\n",
    "\n",
    "  model.add(Connected_layer(outputs=num_classes, activation='Linear'))\n",
    "\n",
    "  model.add(Softmax_layer(spatial=True, groups=1, temperature=1.))\n",
    "  # model.add(Cost_layer(cost_type=cost_type.mse))\n",
    "\n",
    "  # model.compile(optimizer=SGD(lr=0.01, decay=0., lr_min=0., lr_max=np.inf))\n",
    "  model.compile(optimizer=Adam(), metrics=[accuracy])\n",
    "\n",
    "  print('*************************************')\n",
    "  print('\\n Total input dimension: {}'.format(X_train.shape), '\\n')\n",
    "  print('**************MODEL SUMMARY***********')\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  print('\\n***********START TRAINING***********\\n')\n",
    "\n",
    "  # Fit the model on the training set\n",
    "  model.fit(X=X_train, y=y_train, max_iter=10, verbose=True)\n",
    "\n",
    "  print('\\n***********START TESTING**************\\n')\n",
    "\n",
    "  # Test the prediction with timing\n",
    "  loss, out = model.evaluate(X=X_test, truth=y_test, verbose=True)\n",
    "\n",
    "  truth = from_categorical(y_test)\n",
    "  predicted = from_categorical(out)\n",
    "  accuracy  = mean_accuracy_score(truth, predicted)\n",
    "\n",
    "  print('\\nLoss Score: {:.3f}'.format(loss))\n",
    "  print('Accuracy Score: {:.3f}'.format(accuracy))\n",
    "  # SGD : best score I could obtain was 94% with 10 epochs, lr = 0.01 %\n",
    "  # Momentum : best score I could obtain was 93% with 10 epochs\n",
    "  # Adam : best score I could obtain was 95% with 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
